{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "2_notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakigigar/Caltech-CS155-2021/blob/main/psets/set4/2_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLCjfH3NzpDm"
      },
      "source": [
        "# Problem 2 Sample Code\n",
        "\n",
        "This sample code is meant as a guide on how to use PyTorch and how to use the relevant model layers. This not a guide on how to design a network and the network in this example is intentionally designed to have poor performace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9a65gB_zpDo"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSYsFq-PzpDp"
      },
      "source": [
        "## Loading MNIST\n",
        "The `torchvision` module contains links to many standard datasets. We can load the MNIST dataset into a `Dataset` object as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUE36UYfzpDp"
      },
      "source": [
        "train_dataset = datasets.MNIST('./data', train=True, download=True,  # Downloads into a directory ../data\n",
        "                               transform=transforms.ToTensor())\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=False,  # No need to download again\n",
        "                              transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_TNkvLyzpDp"
      },
      "source": [
        "The `Dataset` object is an iterable where each element is a tuple of (input `Tensor`, target):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9aqsk8DzpDp",
        "outputId": "fb538bbd-dcf1-47f8-9b8f-71d8313e9700"
      },
      "source": [
        "print(len(train_dataset), type(train_dataset[0][0]), type(train_dataset[0][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 <class 'torch.Tensor'> <class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYsfhiCezpDq"
      },
      "source": [
        "We can convert images to numpy arrays and plot them with matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX8zMWFDzpDq",
        "outputId": "38553a9b-46f5-4ab7-d68b-4930c671de38"
      },
      "source": [
        "plt.imshow(train_dataset[0][0][0].numpy(), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1749a6dbf48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKRYR5T_zpDr"
      },
      "source": [
        "## Network Definition\n",
        "Let's instantiate a model and take a look at the layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2HyzZFkQzpDr",
        "outputId": "3b4e7e85-331a-44db-eb1a-546e1087a9b2"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    # In problem 2, we don't use the 2D structure of an image at all. Our network\n",
        "    # takes in a flat vector of the pixel values as input.\n",
        "    nn.Flatten(),  \n",
        "    nn.Linear(784, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Flatten()\n",
            "  (1): Linear(in_features=784, out_features=20, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euv9HI6yzpDr"
      },
      "source": [
        "## Training\n",
        "We also choose an optimizer and a loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gDOMhDvzpDs"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXdXGMb2zpDs"
      },
      "source": [
        "We could write our training procedure manually and directly index the `Dataset` objects, but the `DataLoader` object conveniently creates an iterable for automatically creating random minibatches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7dEh-ZBzpDs"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSW9nStkzpDs"
      },
      "source": [
        "We now write our backpropagation loop, training for 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyngiewpzpDs",
        "outputId": "01969520-15a5-4983-9eed-c4c8d1b03647"
      },
      "source": [
        "# Some layers, such as Dropout, behave differently during training\n",
        "model.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    # Track loss each epoch\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1  Loss: 0.7900\n",
            "Train Epoch: 2  Loss: 0.7049\n",
            "Train Epoch: 3  Loss: 0.6281\n",
            "Train Epoch: 4  Loss: 0.6197\n",
            "Train Epoch: 5  Loss: 1.1989\n",
            "Train Epoch: 6  Loss: 0.8405\n",
            "Train Epoch: 7  Loss: 0.6611\n",
            "Train Epoch: 8  Loss: 0.6278\n",
            "Train Epoch: 9  Loss: 0.6922\n",
            "Train Epoch: 10  Loss: 0.8229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2sOFBO2zpDt"
      },
      "source": [
        "## Testing\n",
        "We can perform forward passes through the network without saving gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cprfVo7HzpDt",
        "outputId": "24f879d1-a848-4141-ff73-52e975aa9eae"
      },
      "source": [
        "# Putting layers like Dropout into evaluation mode\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# Turning off automatic differentiation\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        test_loss += loss_fn(output, target).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
        "      (test_loss, correct, len(test_loader.dataset),\n",
        "       100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0086, Accuracy: 9247/10000 (92.4700)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOqWuSrwr2gz"
      },
      "source": [
        "## Training on GPU\n",
        "Google provides the use of free GPU for Colab notebooks, which can accelerate your training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8NmfX7Sr5wY"
      },
      "source": [
        "First, follow Edit > Notebook settings or Runtime>Change runtime type and select **GPU** as Hardware accelerator.\n",
        "\n",
        "Then run the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mfux1Y_r8Zh"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# When you are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKnUnMjAsAXW"
      },
      "source": [
        "\n",
        "Move model to the right device. Then these methods will recursively go over all modules and convert their parameters and buffers to CUDA tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgYE-SXtsIh5"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp4h6kCrsC4n"
      },
      "source": [
        "Remember that you will have to send the inputs and targets at every step to the GPU too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfxWqWZksFXm"
      },
      "source": [
        "model.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    # Track loss each epoch\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXJXGYsHsRLU"
      },
      "source": [
        "# Putting layers like Dropout into evaluation mode\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# Turning off automatic differentiation\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        test_loss += loss_fn(output, target).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
        "      (test_loss, correct, len(test_loader.dataset),\n",
        "       100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2yW6nSsscaE"
      },
      "source": [
        "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
        "is really small."
      ]
    }
  ]
}